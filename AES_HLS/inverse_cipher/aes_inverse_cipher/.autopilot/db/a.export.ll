; ModuleID = 'D:/OneDrive/UVA/crypto/AES_code/VivadoHLS/inverse_cipher/aes_inverse_cipher/.autopilot/db/a.o.2.bc'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-w64-mingw32"

@llvm_global_ctors_1 = appending global [1 x void ()*] [void ()* @_GLOBAL__I_a]
@llvm_global_ctors_0 = appending global [1 x i32] [i32 65535]
@inverse_cipher = internal constant [1280 x i8] c"R\09j\D506\A58\BF@\A3\9E\81\F3\D7\FB|\E39\82\9B/\FF\874\8ECD\C4\DE\E9\CBT{\942\A6\C2#=\EEL\95\0BB\FA\C3N\08.\A1f(\D9$\B2v[\A2Im\8B\D1%r\F8\F6d\86h\98\16\D4\A4\5C\CC]e\B6\92lpHP\FD\ED\B9\DA^\15FW\A7\8D\9D\84\90\D8\AB\00\8C\BC\D3\0A\F7\E4X\05\B8\B3E\06\D0,\1E\8F\CA?\0F\02\C1\AF\BD\03\01\13\8Ak:\91\11AOg\DC\EA\97\F2\CF\CE\F0\B4\E6s\96\ACt\22\E7\AD5\85\E2\F97\E8\1Cu\DFnG\F1\1Aq\1D)\C5\89o\B7b\0E\AA\18\BE\1B\FCV>K\C6\D2y \9A\DB\C0\FEx\CDZ\F4\1F\DD\A83\88\07\C71\B1\12\10Y'\80\EC_`Q\7F\A9\19\B5J\0D-\E5z\9F\93\C9\9C\EF\A0\E0;M\AE*\F5\B0\C8\EB\BB<\83S\99a\17+\04~\BAw\D6&\E1i\14cU!\0C}\00\09\12\1B$-6?HAZSle~w\90\99\82\8B\B4\BD\A6\AF\D8\D1\CA\C3\FC\F5\EE\E7;2) \1F\16\0D\04szahW^EL\AB\A2\B9\B0\8F\86\9D\94\E3\EA\F1\F8\C7\CE\D5\DCv\7FdmR[@I>7,%\1A\13\08\01\E6\EF\F4\FD\C2\CB\D0\D9\AE\A7\BC\B5\8A\83\98\91MD_Vi`{r\05\0C\17\1E!(3:\DD\D4\CF\C6\F9\F0\EB\E2\95\9C\87\8E\B1\B8\A3\AA\EC\E5\FE\F7\C8\C1\DA\D3\A4\AD\B6\BF\80\89\92\9B|ungXQJC4=&/\10\19\02\0B\D7\DE\C5\CC\F3\FA\E1\E8\9F\96\8D\84\BB\B2\A9\A0GNU\5Ccjqx\0F\06\1D\14+\2290\9A\93\88\81\BE\B7\AC\A5\D2\DB\C0\C9\F6\FF\E4\ED\0A\03\18\11.'<5BKPYfot}\A1\A8\B3\BA\85\8C\97\9E\E9\E0\FB\F2\CD\C4\DF\D618#*\15\1C\07\0Eypkb]TOF\00\0B\16\1D,':1XSNEt\7Fbi\B0\BB\A6\AD\9C\97\8A\81\E8\E3\FE\F5\C4\CF\D2\D9{pmfW\5CAJ#(5>\0F\04\19\12\CB\C0\DD\D6\E7\EC\F1\FA\93\98\85\8E\BF\B4\A9\A2\F6\FD\E0\EB\DA\D1\CC\C7\AE\A5\B8\B3\82\89\94\9FFMP[ja|w\1E\15\08\0329$/\8D\86\9B\90\A1\AA\B7\BC\D5\DE\C3\C8\F9\F2\EF\E4=6+ \11\1A\07\0CensxIB_T\F7\FC\E1\EA\DB\D0\CD\C6\AF\A4\B9\B2\83\88\95\9EGLQZk`}v\1F\14\09\0238%.\8C\87\9A\91\A0\AB\B6\BD\D4\DF\C2\C9\F8\F3\EE\E5<7*!\10\1B\06\0DdoryHC^U\01\0A\17\1C-&;0YRODu~ch\B1\BA\A7\AC\9D\96\8B\80\E9\E2\FF\F4\C5\CE\D3\D8zqlgV]@K\22)4?\0E\05\18\13\CA\C1\DC\D7\E6\ED\F0\FB\92\99\84\8F\BE\B5\A8\A3\00\0D\1A\1749.#her\7F\5CQFK\D0\DD\CA\C7\E4\E9\FE\F3\B8\B5\A2\AF\8C\81\96\9B\BB\B6\A1\AC\8F\82\95\98\D3\DE\C9\C4\E7\EA\FD\F0kfq|_REH\03\0E\19\147:- m`wzYTCN\05\08\1F\121<+&\BD\B0\A7\AA\89\84\93\9E\D5\D8\CF\C2\E1\EC\FB\F6\D6\DB\CC\C1\E2\EF\F8\F5\BE\B3\A4\A9\8A\87\90\9D\06\0B\1C\112?(%nctyZW@M\DA\D7\C0\CD\EE\E3\F4\F9\B2\BF\A8\A5\86\8B\9C\91\0A\07\10\1D>3$)boxuV[LAal{vUXOB\09\04\13\1E=0'*\B1\BC\AB\A6\85\88\9F\92\D9\D4\C3\CE\ED\E0\F7\FA\B7\BA\AD\A0\83\8E\99\94\DF\D2\C5\C8\EB\E6\F1\FCgj}pS^ID\0F\02\15\18;6!,\0C\01\16\1B85\22/di~sP]JG\DC\D1\C6\CB\E8\E5\F2\FF\B4\B9\AE\A3\80\8D\9A\97\00\0E\1C\1286$*p~lbHFTZ\E0\EE\FC\F2\D8\D6\C4\CA\90\9E\8C\82\A8\A6\B4\BA\DB\D5\C7\C9\E3\ED\FF\F1\AB\A5\B7\B9\93\9D\8F\81;5')\03\0D\1F\11KEWYs}oa\AD\A3\B1\BF\95\9B\89\87\DD\D3\C1\CF\E5\EB\F9\F7MCQ_u{ig=3!/\05\0B\19\17vxjdN@R\5C\06\08\1A\14>0\22,\96\98\8A\84\AE\A0\B2\BC\E6\E8\FA\F4\DE\D0\C2\CCAO]Sywek1?-#\09\07\15\1B\A1\AF\BD\B3\99\97\85\8B\D1\DF\CD\C3\E9\E7\F5\FB\9A\94\86\88\A2\AC\BE\B0\EA\E4\F6\F8\D2\DC\CE\C0ztfhBL^P\0A\04\16\182<. \EC\E2\F0\FE\D4\DA\C8\C6\9C\92\80\8E\A4\AA\B8\B6\0C\02\10\1E4:(&|r`nDJXV79+%\0F\01\13\1DGI[U\7Fqcm\D7\D9\CB\C5\EF\E1\F3\FD\A7\A9\BB\B5\9F\91\83\8D"
@AES_Decrypt_str = internal unnamed_addr constant [12 x i8] c"AES_Decrypt\00"
@p_str9 = private unnamed_addr constant [7 x i8] c"L_copy\00", align 1
@p_str6 = private unnamed_addr constant [12 x i8] c"AddRoundKey\00", align 1
@p_str5 = private unnamed_addr constant [5 x i8] c"both\00", align 1
@p_str4 = private unnamed_addr constant [5 x i8] c"axis\00", align 1
@p_str10 = private unnamed_addr constant [9 x i8] c"L_rounds\00", align 1
@p_str = private unnamed_addr constant [1 x i8] zeroinitializer, align 1

declare void @llvm.dbg.value(metadata, i64, metadata) nounwind readnone

declare void @llvm.dbg.declare(metadata, metadata) nounwind readnone

define weak void @_ssdm_op_Write.axis.volatile.i8P(i8*, i8) {
entry:
  store i8 %1, i8* %0
  ret void
}

define weak void @_ssdm_op_SpecTopModule(...) {
entry:
  ret void
}

define weak void @_ssdm_op_SpecResourceLimit(...) nounwind {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecRegionEnd(...) {
entry:
  ret i32 0
}

define weak i32 @_ssdm_op_SpecRegionBegin(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecPipeline(...) nounwind {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecLoopTripCount(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecLoopName(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecInterface(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecBitsMap(...) {
entry:
  ret void
}

define weak i8 @_ssdm_op_Read.axis.volatile.i8P(i8*) {
entry:
  %empty = load i8* %0
  ret i8 %empty
}

define weak i16 @_ssdm_op_Read.ap_auto.i16(i16) {
entry:
  ret i16 %0
}

define weak i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56, i8) nounwind readnone {
entry:
  %empty = zext i56 %0 to i64
  %empty_3 = zext i8 %1 to i64
  %empty_4 = shl i64 %empty, 8
  %empty_5 = or i64 %empty_4, %empty_3
  ret i64 %empty_5
}

declare void @_GLOBAL__I_a() nounwind

define internal fastcc void @InvSubBytes([16 x i8]* nocapture %state) noinline {
  %state_addr = getelementptr [16 x i8]* %state, i64 0, i64 0
  %state_load = load i8* %state_addr, align 1
  %tmp_2 = zext i8 %state_load to i64
  %inverse_cipher_addr = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2
  %inverse_cipher_load = load i8* %inverse_cipher_addr, align 1
  store i8 %inverse_cipher_load, i8* %state_addr, align 1
  %state_addr_1 = getelementptr [16 x i8]* %state, i64 0, i64 1
  %state_load_1 = load i8* %state_addr_1, align 1
  %tmp_2_1 = zext i8 %state_load_1 to i64
  %inverse_cipher_addr_1 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_1
  %inverse_cipher_load_1 = load i8* %inverse_cipher_addr_1, align 1
  store i8 %inverse_cipher_load_1, i8* %state_addr_1, align 1
  %state_addr_2 = getelementptr [16 x i8]* %state, i64 0, i64 2
  %state_load_2 = load i8* %state_addr_2, align 1
  %tmp_2_2 = zext i8 %state_load_2 to i64
  %inverse_cipher_addr_2 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_2
  %inverse_cipher_load_2 = load i8* %inverse_cipher_addr_2, align 1
  store i8 %inverse_cipher_load_2, i8* %state_addr_2, align 1
  %state_addr_3 = getelementptr [16 x i8]* %state, i64 0, i64 3
  %state_load_3 = load i8* %state_addr_3, align 1
  %tmp_2_3 = zext i8 %state_load_3 to i64
  %inverse_cipher_addr_3 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_3
  %inverse_cipher_load_3 = load i8* %inverse_cipher_addr_3, align 1
  store i8 %inverse_cipher_load_3, i8* %state_addr_3, align 1
  %state_addr_4 = getelementptr [16 x i8]* %state, i64 0, i64 4
  %state_load_4 = load i8* %state_addr_4, align 1
  %tmp_2_4 = zext i8 %state_load_4 to i64
  %inverse_cipher_addr_4 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_4
  %inverse_cipher_load_4 = load i8* %inverse_cipher_addr_4, align 1
  store i8 %inverse_cipher_load_4, i8* %state_addr_4, align 1
  %state_addr_5 = getelementptr [16 x i8]* %state, i64 0, i64 5
  %state_load_5 = load i8* %state_addr_5, align 1
  %tmp_2_5 = zext i8 %state_load_5 to i64
  %inverse_cipher_addr_5 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_5
  %inverse_cipher_load_5 = load i8* %inverse_cipher_addr_5, align 1
  store i8 %inverse_cipher_load_5, i8* %state_addr_5, align 1
  %state_addr_6 = getelementptr [16 x i8]* %state, i64 0, i64 6
  %state_load_6 = load i8* %state_addr_6, align 1
  %tmp_2_6 = zext i8 %state_load_6 to i64
  %inverse_cipher_addr_6 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_6
  %inverse_cipher_load_6 = load i8* %inverse_cipher_addr_6, align 1
  store i8 %inverse_cipher_load_6, i8* %state_addr_6, align 1
  %state_addr_7 = getelementptr [16 x i8]* %state, i64 0, i64 7
  %state_load_7 = load i8* %state_addr_7, align 1
  %tmp_2_7 = zext i8 %state_load_7 to i64
  %inverse_cipher_addr_7 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_7
  %inverse_cipher_load_7 = load i8* %inverse_cipher_addr_7, align 1
  store i8 %inverse_cipher_load_7, i8* %state_addr_7, align 1
  %state_addr_8 = getelementptr [16 x i8]* %state, i64 0, i64 8
  %state_load_8 = load i8* %state_addr_8, align 1
  %tmp_2_8 = zext i8 %state_load_8 to i64
  %inverse_cipher_addr_8 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_8
  %inverse_cipher_load_8 = load i8* %inverse_cipher_addr_8, align 1
  store i8 %inverse_cipher_load_8, i8* %state_addr_8, align 1
  %state_addr_9 = getelementptr [16 x i8]* %state, i64 0, i64 9
  %state_load_9 = load i8* %state_addr_9, align 1
  %tmp_2_9 = zext i8 %state_load_9 to i64
  %inverse_cipher_addr_9 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_9
  %inverse_cipher_load_9 = load i8* %inverse_cipher_addr_9, align 1
  store i8 %inverse_cipher_load_9, i8* %state_addr_9, align 1
  %state_addr_10 = getelementptr [16 x i8]* %state, i64 0, i64 10
  %state_load_10 = load i8* %state_addr_10, align 1
  %tmp_2_s = zext i8 %state_load_10 to i64
  %inverse_cipher_addr_10 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_s
  %inverse_cipher_load_10 = load i8* %inverse_cipher_addr_10, align 1
  store i8 %inverse_cipher_load_10, i8* %state_addr_10, align 1
  %state_addr_11 = getelementptr [16 x i8]* %state, i64 0, i64 11
  %state_load_11 = load i8* %state_addr_11, align 1
  %tmp_2_10 = zext i8 %state_load_11 to i64
  %inverse_cipher_addr_11 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_10
  %inverse_cipher_load_11 = load i8* %inverse_cipher_addr_11, align 1
  store i8 %inverse_cipher_load_11, i8* %state_addr_11, align 1
  %state_addr_12 = getelementptr [16 x i8]* %state, i64 0, i64 12
  %state_load_12 = load i8* %state_addr_12, align 1
  %tmp_2_11 = zext i8 %state_load_12 to i64
  %inverse_cipher_addr_12 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_11
  %inverse_cipher_load_12 = load i8* %inverse_cipher_addr_12, align 1
  store i8 %inverse_cipher_load_12, i8* %state_addr_12, align 1
  %state_addr_13 = getelementptr [16 x i8]* %state, i64 0, i64 13
  %state_load_13 = load i8* %state_addr_13, align 1
  %tmp_2_12 = zext i8 %state_load_13 to i64
  %inverse_cipher_addr_13 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_12
  %inverse_cipher_load_13 = load i8* %inverse_cipher_addr_13, align 1
  store i8 %inverse_cipher_load_13, i8* %state_addr_13, align 1
  %state_addr_14 = getelementptr [16 x i8]* %state, i64 0, i64 14
  %state_load_14 = load i8* %state_addr_14, align 1
  %tmp_2_13 = zext i8 %state_load_14 to i64
  %inverse_cipher_addr_14 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_13
  %inverse_cipher_load_14 = load i8* %inverse_cipher_addr_14, align 1
  store i8 %inverse_cipher_load_14, i8* %state_addr_14, align 1
  %state_addr_15 = getelementptr [16 x i8]* %state, i64 0, i64 15
  %state_load_15 = load i8* %state_addr_15, align 1
  %tmp_2_14 = zext i8 %state_load_15 to i64
  %inverse_cipher_addr_15 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %tmp_2_14
  %inverse_cipher_load_15 = load i8* %inverse_cipher_addr_15, align 1
  store i8 %inverse_cipher_load_15, i8* %state_addr_15, align 1
  ret void
}

define internal fastcc void @InvShiftRows([16 x i8]* nocapture %state) noinline {
  %state_addr = getelementptr [16 x i8]* %state, i64 0, i64 0
  %tmp_state = alloca [16 x i8], align 16
  %state_load = load i8* %state_addr, align 1
  %tmp_state_addr = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 0
  store i8 %state_load, i8* %tmp_state_addr, align 16
  %state_addr_17 = getelementptr [16 x i8]* %state, i64 0, i64 13
  %state_load_1 = load i8* %state_addr_17, align 1
  %tmp_state_addr_1 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 1
  store i8 %state_load_1, i8* %tmp_state_addr_1, align 1
  %state_addr_16 = getelementptr [16 x i8]* %state, i64 0, i64 10
  %state_load_2 = load i8* %state_addr_16, align 1
  %tmp_state_addr_2 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 2
  store i8 %state_load_2, i8* %tmp_state_addr_2, align 2
  %state_addr_18 = getelementptr [16 x i8]* %state, i64 0, i64 7
  %state_load_3 = load i8* %state_addr_18, align 1
  %tmp_state_addr_3 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 3
  store i8 %state_load_3, i8* %tmp_state_addr_3, align 1
  %state_addr_19 = getelementptr [16 x i8]* %state, i64 0, i64 4
  %state_load_4 = load i8* %state_addr_19, align 1
  %tmp_state_addr_4 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 4
  store i8 %state_load_4, i8* %tmp_state_addr_4, align 4
  %state_addr_20 = getelementptr [16 x i8]* %state, i64 0, i64 1
  %state_load_5 = load i8* %state_addr_20, align 1
  %tmp_state_addr_5 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 5
  store i8 %state_load_5, i8* %tmp_state_addr_5, align 1
  %state_addr_21 = getelementptr [16 x i8]* %state, i64 0, i64 14
  %state_load_6 = load i8* %state_addr_21, align 1
  %tmp_state_addr_6 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 6
  store i8 %state_load_6, i8* %tmp_state_addr_6, align 2
  %state_addr_22 = getelementptr [16 x i8]* %state, i64 0, i64 11
  %state_load_7 = load i8* %state_addr_22, align 1
  %tmp_state_addr_7 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 7
  store i8 %state_load_7, i8* %tmp_state_addr_7, align 1
  %state_addr_23 = getelementptr [16 x i8]* %state, i64 0, i64 8
  %state_load_8 = load i8* %state_addr_23, align 1
  %tmp_state_addr_8 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 8
  store i8 %state_load_8, i8* %tmp_state_addr_8, align 8
  %state_addr_24 = getelementptr [16 x i8]* %state, i64 0, i64 5
  %state_load_9 = load i8* %state_addr_24, align 1
  %tmp_state_addr_9 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 9
  store i8 %state_load_9, i8* %tmp_state_addr_9, align 1
  %state_addr_25 = getelementptr [16 x i8]* %state, i64 0, i64 2
  %state_load_10 = load i8* %state_addr_25, align 1
  %tmp_state_addr_10 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 10
  store i8 %state_load_10, i8* %tmp_state_addr_10, align 2
  %state_addr_26 = getelementptr [16 x i8]* %state, i64 0, i64 15
  %state_load_11 = load i8* %state_addr_26, align 1
  %tmp_state_addr_11 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 11
  store i8 %state_load_11, i8* %tmp_state_addr_11, align 1
  %state_addr_27 = getelementptr [16 x i8]* %state, i64 0, i64 12
  %state_load_12 = load i8* %state_addr_27, align 1
  %tmp_state_addr_12 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 12
  store i8 %state_load_12, i8* %tmp_state_addr_12, align 4
  %state_addr_28 = getelementptr [16 x i8]* %state, i64 0, i64 9
  %state_load_13 = load i8* %state_addr_28, align 1
  %tmp_state_addr_13 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 13
  store i8 %state_load_13, i8* %tmp_state_addr_13, align 1
  %state_addr_29 = getelementptr [16 x i8]* %state, i64 0, i64 6
  %state_load_14 = load i8* %state_addr_29, align 1
  %tmp_state_addr_14 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 14
  store i8 %state_load_14, i8* %tmp_state_addr_14, align 2
  %state_addr_30 = getelementptr [16 x i8]* %state, i64 0, i64 3
  %state_load_15 = load i8* %state_addr_30, align 1
  %tmp_state_addr_15 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 15
  store i8 %state_load_15, i8* %tmp_state_addr_15, align 1
  br label %1

; <label>:1                                       ; preds = %2, %0
  %i = phi i5 [ 0, %0 ], [ %i_1, %2 ]
  %tmp = icmp eq i5 %i, -16
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 16, i64 16, i64 16)
  %i_1 = add i5 %i, 1
  br i1 %tmp, label %3, label %2

; <label>:2                                       ; preds = %1
  %tmp_4 = zext i5 %i to i64
  %tmp_state_addr_16 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 %tmp_4
  %tmp_state_load = load i8* %tmp_state_addr_16, align 1
  %state_addr_31 = getelementptr [16 x i8]* %state, i64 0, i64 %tmp_4
  store i8 %tmp_state_load, i8* %state_addr_31, align 1
  br label %1

; <label>:3                                       ; preds = %1
  ret void
}

define internal fastcc void @InvMixColumns([16 x i8]* nocapture %state) noinline {
  %state_addr = getelementptr [16 x i8]* %state, i64 0, i64 0
  %tmp_state = alloca [16 x i8], align 16
  %state_load = load i8* %state_addr, align 1
  %addr = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load)
  %inverse_cipher_addr = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr
  %inverse_cipher_load = load i8* %inverse_cipher_addr, align 1
  %state_addr_32 = getelementptr [16 x i8]* %state, i64 0, i64 1
  %state_load_16 = load i8* %state_addr_32, align 1
  %addr1 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_16)
  %inverse_cipher_addr_16 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr1
  %inverse_cipher_load_16 = load i8* %inverse_cipher_addr_16, align 1
  %state_addr_33 = getelementptr [16 x i8]* %state, i64 0, i64 2
  %state_load_17 = load i8* %state_addr_33, align 1
  %addr2 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_17)
  %inverse_cipher_addr_17 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr2
  %inverse_cipher_load_17 = load i8* %inverse_cipher_addr_17, align 1
  %state_addr_34 = getelementptr [16 x i8]* %state, i64 0, i64 3
  %state_load_18 = load i8* %state_addr_34, align 1
  %addr3 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_18)
  %inverse_cipher_addr_18 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr3
  %inverse_cipher_load_18 = load i8* %inverse_cipher_addr_18, align 1
  %tmp1 = xor i8 %inverse_cipher_load_16, %inverse_cipher_load
  %tmp2 = xor i8 %inverse_cipher_load_17, %inverse_cipher_load_18
  %tmp_1 = xor i8 %tmp2, %tmp1
  %tmp_state_addr = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 0
  store i8 %tmp_1, i8* %tmp_state_addr, align 16
  %addr4 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load)
  %inverse_cipher_addr_19 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr4
  %inverse_cipher_load_19 = load i8* %inverse_cipher_addr_19, align 1
  %addr5 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_16)
  %inverse_cipher_addr_20 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr5
  %inverse_cipher_load_20 = load i8* %inverse_cipher_addr_20, align 1
  %addr6 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_17)
  %inverse_cipher_addr_21 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr6
  %inverse_cipher_load_21 = load i8* %inverse_cipher_addr_21, align 1
  %addr7 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_18)
  %inverse_cipher_addr_22 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr7
  %inverse_cipher_load_22 = load i8* %inverse_cipher_addr_22, align 1
  %tmp3 = xor i8 %inverse_cipher_load_20, %inverse_cipher_load_19
  %tmp4 = xor i8 %inverse_cipher_load_21, %inverse_cipher_load_22
  %tmp_4 = xor i8 %tmp4, %tmp3
  %tmp_state_addr_17 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 1
  store i8 %tmp_4, i8* %tmp_state_addr_17, align 1
  %addr8 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load)
  %inverse_cipher_addr_23 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr8
  %inverse_cipher_load_23 = load i8* %inverse_cipher_addr_23, align 1
  %addr9 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_16)
  %inverse_cipher_addr_24 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr9
  %inverse_cipher_load_24 = load i8* %inverse_cipher_addr_24, align 1
  %addr10 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_17)
  %inverse_cipher_addr_25 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr10
  %inverse_cipher_load_25 = load i8* %inverse_cipher_addr_25, align 1
  %addr11 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_18)
  %inverse_cipher_addr_26 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr11
  %inverse_cipher_load_26 = load i8* %inverse_cipher_addr_26, align 1
  %tmp5 = xor i8 %inverse_cipher_load_24, %inverse_cipher_load_23
  %tmp6 = xor i8 %inverse_cipher_load_25, %inverse_cipher_load_26
  %tmp_s = xor i8 %tmp6, %tmp5
  %tmp_state_addr_18 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 2
  store i8 %tmp_s, i8* %tmp_state_addr_18, align 2
  %addr12 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load)
  %inverse_cipher_addr_27 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr12
  %inverse_cipher_load_27 = load i8* %inverse_cipher_addr_27, align 1
  %addr13 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_16)
  %inverse_cipher_addr_28 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr13
  %inverse_cipher_load_28 = load i8* %inverse_cipher_addr_28, align 1
  %addr14 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_17)
  %inverse_cipher_addr_29 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr14
  %inverse_cipher_load_29 = load i8* %inverse_cipher_addr_29, align 1
  %addr15 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_18)
  %inverse_cipher_addr_30 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr15
  %inverse_cipher_load_30 = load i8* %inverse_cipher_addr_30, align 1
  %tmp7 = xor i8 %inverse_cipher_load_28, %inverse_cipher_load_27
  %tmp8 = xor i8 %inverse_cipher_load_29, %inverse_cipher_load_30
  %tmp_2 = xor i8 %tmp8, %tmp7
  %tmp_state_addr_19 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 3
  store i8 %tmp_2, i8* %tmp_state_addr_19, align 1
  %state_addr_35 = getelementptr [16 x i8]* %state, i64 0, i64 4
  %state_load_19 = load i8* %state_addr_35, align 1
  %addr16 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_19)
  %inverse_cipher_addr_31 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr16
  %inverse_cipher_load_31 = load i8* %inverse_cipher_addr_31, align 1
  %state_addr_36 = getelementptr [16 x i8]* %state, i64 0, i64 5
  %state_load_20 = load i8* %state_addr_36, align 1
  %addr17 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_20)
  %inverse_cipher_addr_32 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr17
  %inverse_cipher_load_32 = load i8* %inverse_cipher_addr_32, align 1
  %state_addr_37 = getelementptr [16 x i8]* %state, i64 0, i64 6
  %state_load_21 = load i8* %state_addr_37, align 1
  %addr18 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_21)
  %inverse_cipher_addr_33 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr18
  %inverse_cipher_load_33 = load i8* %inverse_cipher_addr_33, align 1
  %state_addr_38 = getelementptr [16 x i8]* %state, i64 0, i64 7
  %state_load_22 = load i8* %state_addr_38, align 1
  %addr19 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_22)
  %inverse_cipher_addr_34 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr19
  %inverse_cipher_load_34 = load i8* %inverse_cipher_addr_34, align 1
  %tmp9 = xor i8 %inverse_cipher_load_32, %inverse_cipher_load_31
  %tmp = xor i8 %inverse_cipher_load_33, %inverse_cipher_load_34
  %tmp_3 = xor i8 %tmp, %tmp9
  %tmp_state_addr_20 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 4
  store i8 %tmp_3, i8* %tmp_state_addr_20, align 4
  %addr20 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_19)
  %inverse_cipher_addr_35 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr20
  %inverse_cipher_load_35 = load i8* %inverse_cipher_addr_35, align 1
  %addr21 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_20)
  %inverse_cipher_addr_36 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr21
  %inverse_cipher_load_36 = load i8* %inverse_cipher_addr_36, align 1
  %addr22 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_21)
  %inverse_cipher_addr_37 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr22
  %inverse_cipher_load_37 = load i8* %inverse_cipher_addr_37, align 1
  %addr23 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_22)
  %inverse_cipher_addr_38 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr23
  %inverse_cipher_load_38 = load i8* %inverse_cipher_addr_38, align 1
  %tmp10 = xor i8 %inverse_cipher_load_36, %inverse_cipher_load_35
  %tmp11 = xor i8 %inverse_cipher_load_37, %inverse_cipher_load_38
  %tmp_5 = xor i8 %tmp11, %tmp10
  %tmp_state_addr_21 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 5
  store i8 %tmp_5, i8* %tmp_state_addr_21, align 1
  %addr24 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_19)
  %inverse_cipher_addr_39 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr24
  %inverse_cipher_load_39 = load i8* %inverse_cipher_addr_39, align 1
  %addr25 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_20)
  %inverse_cipher_addr_40 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr25
  %inverse_cipher_load_40 = load i8* %inverse_cipher_addr_40, align 1
  %addr26 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_21)
  %inverse_cipher_addr_41 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr26
  %inverse_cipher_load_41 = load i8* %inverse_cipher_addr_41, align 1
  %addr27 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_22)
  %inverse_cipher_addr_42 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr27
  %inverse_cipher_load_42 = load i8* %inverse_cipher_addr_42, align 1
  %tmp12 = xor i8 %inverse_cipher_load_40, %inverse_cipher_load_39
  %tmp13 = xor i8 %inverse_cipher_load_41, %inverse_cipher_load_42
  %tmp_6 = xor i8 %tmp13, %tmp12
  %tmp_state_addr_22 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 6
  store i8 %tmp_6, i8* %tmp_state_addr_22, align 2
  %addr28 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_19)
  %inverse_cipher_addr_43 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr28
  %inverse_cipher_load_43 = load i8* %inverse_cipher_addr_43, align 1
  %addr29 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_20)
  %inverse_cipher_addr_44 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr29
  %inverse_cipher_load_44 = load i8* %inverse_cipher_addr_44, align 1
  %addr30 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_21)
  %inverse_cipher_addr_45 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr30
  %inverse_cipher_load_45 = load i8* %inverse_cipher_addr_45, align 1
  %addr31 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_22)
  %inverse_cipher_addr_46 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr31
  %inverse_cipher_load_46 = load i8* %inverse_cipher_addr_46, align 1
  %tmp14 = xor i8 %inverse_cipher_load_44, %inverse_cipher_load_43
  %tmp15 = xor i8 %inverse_cipher_load_45, %inverse_cipher_load_46
  %tmp_7 = xor i8 %tmp15, %tmp14
  %tmp_state_addr_23 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 7
  store i8 %tmp_7, i8* %tmp_state_addr_23, align 1
  %state_addr_39 = getelementptr [16 x i8]* %state, i64 0, i64 8
  %state_load_23 = load i8* %state_addr_39, align 1
  %addr32 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_23)
  %inverse_cipher_addr_47 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr32
  %inverse_cipher_load_47 = load i8* %inverse_cipher_addr_47, align 1
  %state_addr_40 = getelementptr [16 x i8]* %state, i64 0, i64 9
  %state_load_24 = load i8* %state_addr_40, align 1
  %addr33 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_24)
  %inverse_cipher_addr_48 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr33
  %inverse_cipher_load_48 = load i8* %inverse_cipher_addr_48, align 1
  %state_addr_41 = getelementptr [16 x i8]* %state, i64 0, i64 10
  %state_load_25 = load i8* %state_addr_41, align 1
  %addr34 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_25)
  %inverse_cipher_addr_49 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr34
  %inverse_cipher_load_49 = load i8* %inverse_cipher_addr_49, align 1
  %state_addr_42 = getelementptr [16 x i8]* %state, i64 0, i64 11
  %state_load_26 = load i8* %state_addr_42, align 1
  %addr35 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_26)
  %inverse_cipher_addr_50 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr35
  %inverse_cipher_load_50 = load i8* %inverse_cipher_addr_50, align 1
  %tmp16 = xor i8 %inverse_cipher_load_48, %inverse_cipher_load_47
  %tmp17 = xor i8 %inverse_cipher_load_49, %inverse_cipher_load_50
  %tmp_8 = xor i8 %tmp17, %tmp16
  %tmp_state_addr_24 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 8
  store i8 %tmp_8, i8* %tmp_state_addr_24, align 8
  %addr36 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_23)
  %inverse_cipher_addr_51 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr36
  %inverse_cipher_load_51 = load i8* %inverse_cipher_addr_51, align 1
  %addr37 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_24)
  %inverse_cipher_addr_52 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr37
  %inverse_cipher_load_52 = load i8* %inverse_cipher_addr_52, align 1
  %addr38 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_25)
  %inverse_cipher_addr_53 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr38
  %inverse_cipher_load_53 = load i8* %inverse_cipher_addr_53, align 1
  %addr39 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_26)
  %inverse_cipher_addr_54 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr39
  %inverse_cipher_load_54 = load i8* %inverse_cipher_addr_54, align 1
  %tmp18 = xor i8 %inverse_cipher_load_52, %inverse_cipher_load_51
  %tmp19 = xor i8 %inverse_cipher_load_53, %inverse_cipher_load_54
  %tmp_9 = xor i8 %tmp19, %tmp18
  %tmp_state_addr_25 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 9
  store i8 %tmp_9, i8* %tmp_state_addr_25, align 1
  %addr40 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_23)
  %inverse_cipher_addr_55 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr40
  %inverse_cipher_load_55 = load i8* %inverse_cipher_addr_55, align 1
  %addr41 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_24)
  %inverse_cipher_addr_56 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr41
  %inverse_cipher_load_56 = load i8* %inverse_cipher_addr_56, align 1
  %addr42 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_25)
  %inverse_cipher_addr_57 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr42
  %inverse_cipher_load_57 = load i8* %inverse_cipher_addr_57, align 1
  %addr43 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_26)
  %inverse_cipher_addr_58 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr43
  %inverse_cipher_load_58 = load i8* %inverse_cipher_addr_58, align 1
  %tmp20 = xor i8 %inverse_cipher_load_56, %inverse_cipher_load_55
  %tmp21 = xor i8 %inverse_cipher_load_57, %inverse_cipher_load_58
  %tmp_10 = xor i8 %tmp21, %tmp20
  %tmp_state_addr_26 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 10
  store i8 %tmp_10, i8* %tmp_state_addr_26, align 2
  %addr44 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_23)
  %inverse_cipher_addr_59 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr44
  %inverse_cipher_load_59 = load i8* %inverse_cipher_addr_59, align 1
  %addr45 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_24)
  %inverse_cipher_addr_60 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr45
  %inverse_cipher_load_60 = load i8* %inverse_cipher_addr_60, align 1
  %addr46 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_25)
  %inverse_cipher_addr_61 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr46
  %inverse_cipher_load_61 = load i8* %inverse_cipher_addr_61, align 1
  %addr47 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_26)
  %inverse_cipher_addr_62 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr47
  %inverse_cipher_load_62 = load i8* %inverse_cipher_addr_62, align 1
  %tmp22 = xor i8 %inverse_cipher_load_60, %inverse_cipher_load_59
  %tmp23 = xor i8 %inverse_cipher_load_61, %inverse_cipher_load_62
  %tmp_11 = xor i8 %tmp23, %tmp22
  %tmp_state_addr_27 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 11
  store i8 %tmp_11, i8* %tmp_state_addr_27, align 1
  %state_addr_43 = getelementptr [16 x i8]* %state, i64 0, i64 12
  %state_load_27 = load i8* %state_addr_43, align 1
  %addr48 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_27)
  %inverse_cipher_addr_63 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr48
  %inverse_cipher_load_63 = load i8* %inverse_cipher_addr_63, align 1
  %state_addr_44 = getelementptr [16 x i8]* %state, i64 0, i64 13
  %state_load_28 = load i8* %state_addr_44, align 1
  %addr49 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_28)
  %inverse_cipher_addr_64 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr49
  %inverse_cipher_load_64 = load i8* %inverse_cipher_addr_64, align 1
  %state_addr_45 = getelementptr [16 x i8]* %state, i64 0, i64 14
  %state_load_29 = load i8* %state_addr_45, align 1
  %addr50 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_29)
  %inverse_cipher_addr_65 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr50
  %inverse_cipher_load_65 = load i8* %inverse_cipher_addr_65, align 1
  %state_addr_46 = getelementptr [16 x i8]* %state, i64 0, i64 15
  %state_load_30 = load i8* %state_addr_46, align 1
  %addr51 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_30)
  %inverse_cipher_addr_66 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr51
  %inverse_cipher_load_66 = load i8* %inverse_cipher_addr_66, align 1
  %tmp24 = xor i8 %inverse_cipher_load_64, %inverse_cipher_load_63
  %tmp25 = xor i8 %inverse_cipher_load_65, %inverse_cipher_load_66
  %tmp_12 = xor i8 %tmp25, %tmp24
  %tmp_state_addr_28 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 12
  store i8 %tmp_12, i8* %tmp_state_addr_28, align 4
  %addr52 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_27)
  %inverse_cipher_addr_67 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr52
  %inverse_cipher_load_67 = load i8* %inverse_cipher_addr_67, align 1
  %addr53 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_28)
  %inverse_cipher_addr_68 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr53
  %inverse_cipher_load_68 = load i8* %inverse_cipher_addr_68, align 1
  %addr54 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_29)
  %inverse_cipher_addr_69 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr54
  %inverse_cipher_load_69 = load i8* %inverse_cipher_addr_69, align 1
  %addr55 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_30)
  %inverse_cipher_addr_70 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr55
  %inverse_cipher_load_70 = load i8* %inverse_cipher_addr_70, align 1
  %tmp26 = xor i8 %inverse_cipher_load_68, %inverse_cipher_load_67
  %tmp27 = xor i8 %inverse_cipher_load_69, %inverse_cipher_load_70
  %tmp_13 = xor i8 %tmp27, %tmp26
  %tmp_state_addr_29 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 13
  store i8 %tmp_13, i8* %tmp_state_addr_29, align 1
  %addr56 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_27)
  %inverse_cipher_addr_71 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr56
  %inverse_cipher_load_71 = load i8* %inverse_cipher_addr_71, align 1
  %addr57 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_28)
  %inverse_cipher_addr_72 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr57
  %inverse_cipher_load_72 = load i8* %inverse_cipher_addr_72, align 1
  %addr58 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_29)
  %inverse_cipher_addr_73 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr58
  %inverse_cipher_load_73 = load i8* %inverse_cipher_addr_73, align 1
  %addr59 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_30)
  %inverse_cipher_addr_74 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr59
  %inverse_cipher_load_74 = load i8* %inverse_cipher_addr_74, align 1
  %tmp28 = xor i8 %inverse_cipher_load_72, %inverse_cipher_load_71
  %tmp29 = xor i8 %inverse_cipher_load_73, %inverse_cipher_load_74
  %tmp_14 = xor i8 %tmp29, %tmp28
  %tmp_state_addr_30 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 14
  store i8 %tmp_14, i8* %tmp_state_addr_30, align 2
  %addr60 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 2, i8 %state_load_27)
  %inverse_cipher_addr_75 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr60
  %inverse_cipher_load_75 = load i8* %inverse_cipher_addr_75, align 1
  %addr61 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 3, i8 %state_load_28)
  %inverse_cipher_addr_76 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr61
  %inverse_cipher_load_76 = load i8* %inverse_cipher_addr_76, align 1
  %addr62 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 1, i8 %state_load_29)
  %inverse_cipher_addr_77 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr62
  %inverse_cipher_load_77 = load i8* %inverse_cipher_addr_77, align 1
  %addr63 = call i64 @_ssdm_op_BitConcatenate.i64.i56.i8(i56 4, i8 %state_load_30)
  %inverse_cipher_addr_78 = getelementptr [1280 x i8]* @inverse_cipher, i64 0, i64 %addr63
  %inverse_cipher_load_78 = load i8* %inverse_cipher_addr_78, align 1
  %tmp30 = xor i8 %inverse_cipher_load_76, %inverse_cipher_load_75
  %tmp31 = xor i8 %inverse_cipher_load_77, %inverse_cipher_load_78
  %tmp_15 = xor i8 %tmp31, %tmp30
  %tmp_state_addr_31 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 15
  store i8 %tmp_15, i8* %tmp_state_addr_31, align 1
  br label %1

; <label>:1                                       ; preds = %2, %0
  %i = phi i5 [ 0, %0 ], [ %i_2, %2 ]
  %tmp_16 = icmp eq i5 %i, -16
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 16, i64 16, i64 16)
  %i_2 = add i5 %i, 1
  br i1 %tmp_16, label %3, label %2

; <label>:2                                       ; preds = %1
  %tmp_17 = zext i5 %i to i64
  %tmp_state_addr_32 = getelementptr inbounds [16 x i8]* %tmp_state, i64 0, i64 %tmp_17
  %tmp_state_load = load i8* %tmp_state_addr_32, align 1
  %state_addr_47 = getelementptr [16 x i8]* %state, i64 0, i64 %tmp_17
  store i8 %tmp_state_load, i8* %state_addr_47, align 1
  br label %1

; <label>:3                                       ; preds = %1
  ret void
}

define internal fastcc void @AddRoundKey([16 x i8]* nocapture %state, i8* %roundKey) noinline {
  call void (...)* @_ssdm_op_SpecInterface(i8* %roundKey, [5 x i8]* @p_str4, i32 0, i32 0, [5 x i8]* @p_str5, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %roundKey_read = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr = getelementptr [16 x i8]* %state, i64 0, i64 0
  %state_load = load i8* %state_addr, align 1
  %tmp_s = xor i8 %state_load, %roundKey_read
  store i8 %tmp_s, i8* %state_addr, align 1
  %roundKey_read_1 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_48 = getelementptr [16 x i8]* %state, i64 0, i64 1
  %state_load_1 = load i8* %state_addr_48, align 1
  %tmp_65_1 = xor i8 %state_load_1, %roundKey_read_1
  store i8 %tmp_65_1, i8* %state_addr_48, align 1
  %roundKey_read_2 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_49 = getelementptr [16 x i8]* %state, i64 0, i64 2
  %state_load_2 = load i8* %state_addr_49, align 1
  %tmp_65_2 = xor i8 %state_load_2, %roundKey_read_2
  store i8 %tmp_65_2, i8* %state_addr_49, align 1
  %roundKey_read_3 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_50 = getelementptr [16 x i8]* %state, i64 0, i64 3
  %state_load_3 = load i8* %state_addr_50, align 1
  %tmp_65_3 = xor i8 %state_load_3, %roundKey_read_3
  store i8 %tmp_65_3, i8* %state_addr_50, align 1
  %roundKey_read_4 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_51 = getelementptr [16 x i8]* %state, i64 0, i64 4
  %state_load_4 = load i8* %state_addr_51, align 1
  %tmp_65_4 = xor i8 %state_load_4, %roundKey_read_4
  store i8 %tmp_65_4, i8* %state_addr_51, align 1
  %roundKey_read_5 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_52 = getelementptr [16 x i8]* %state, i64 0, i64 5
  %state_load_5 = load i8* %state_addr_52, align 1
  %tmp_65_5 = xor i8 %state_load_5, %roundKey_read_5
  store i8 %tmp_65_5, i8* %state_addr_52, align 1
  %roundKey_read_6 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_53 = getelementptr [16 x i8]* %state, i64 0, i64 6
  %state_load_6 = load i8* %state_addr_53, align 1
  %tmp_65_6 = xor i8 %state_load_6, %roundKey_read_6
  store i8 %tmp_65_6, i8* %state_addr_53, align 1
  %roundKey_read_7 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_54 = getelementptr [16 x i8]* %state, i64 0, i64 7
  %state_load_7 = load i8* %state_addr_54, align 1
  %tmp_65_7 = xor i8 %state_load_7, %roundKey_read_7
  store i8 %tmp_65_7, i8* %state_addr_54, align 1
  %roundKey_read_8 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_55 = getelementptr [16 x i8]* %state, i64 0, i64 8
  %state_load_8 = load i8* %state_addr_55, align 1
  %tmp_65_8 = xor i8 %state_load_8, %roundKey_read_8
  store i8 %tmp_65_8, i8* %state_addr_55, align 1
  %roundKey_read_9 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_56 = getelementptr [16 x i8]* %state, i64 0, i64 9
  %state_load_9 = load i8* %state_addr_56, align 1
  %tmp_65_9 = xor i8 %state_load_9, %roundKey_read_9
  store i8 %tmp_65_9, i8* %state_addr_56, align 1
  %roundKey_read_10 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_57 = getelementptr [16 x i8]* %state, i64 0, i64 10
  %state_load_10 = load i8* %state_addr_57, align 1
  %tmp_65_s = xor i8 %state_load_10, %roundKey_read_10
  store i8 %tmp_65_s, i8* %state_addr_57, align 1
  %roundKey_read_11 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_58 = getelementptr [16 x i8]* %state, i64 0, i64 11
  %state_load_11 = load i8* %state_addr_58, align 1
  %tmp_65_10 = xor i8 %state_load_11, %roundKey_read_11
  store i8 %tmp_65_10, i8* %state_addr_58, align 1
  %roundKey_read_12 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_59 = getelementptr [16 x i8]* %state, i64 0, i64 12
  %state_load_12 = load i8* %state_addr_59, align 1
  %tmp_65_11 = xor i8 %state_load_12, %roundKey_read_12
  store i8 %tmp_65_11, i8* %state_addr_59, align 1
  %roundKey_read_13 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_60 = getelementptr [16 x i8]* %state, i64 0, i64 13
  %state_load_13 = load i8* %state_addr_60, align 1
  %tmp_65_12 = xor i8 %state_load_13, %roundKey_read_13
  store i8 %tmp_65_12, i8* %state_addr_60, align 1
  %roundKey_read_14 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_61 = getelementptr [16 x i8]* %state, i64 0, i64 14
  %state_load_14 = load i8* %state_addr_61, align 1
  %tmp_65_13 = xor i8 %state_load_14, %roundKey_read_14
  store i8 %tmp_65_13, i8* %state_addr_61, align 1
  %roundKey_read_15 = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %roundKey)
  %state_addr_62 = getelementptr [16 x i8]* %state, i64 0, i64 15
  %state_load_15 = load i8* %state_addr_62, align 1
  %tmp_65_14 = xor i8 %state_load_15, %roundKey_read_15
  store i8 %tmp_65_14, i8* %state_addr_62, align 1
  ret void
}

define void @AES_Decrypt(i8* %ciphertext, i8* %expandedKey, i16 zeroext %Nr, i8* %plaintext) nounwind uwtable {
  call void (...)* @_ssdm_op_SpecBitsMap(i8* %ciphertext) nounwind, !map !34
  call void (...)* @_ssdm_op_SpecBitsMap(i8* %expandedKey) nounwind, !map !40
  call void (...)* @_ssdm_op_SpecBitsMap(i16 %Nr) nounwind, !map !46
  call void (...)* @_ssdm_op_SpecBitsMap(i8* %plaintext) nounwind, !map !52
  call void (...)* @_ssdm_op_SpecTopModule([12 x i8]* @AES_Decrypt_str) nounwind
  %Nr_read = call i16 @_ssdm_op_Read.ap_auto.i16(i16 %Nr) nounwind
  %state = alloca [16 x i8], align 16
  call void (...)* @_ssdm_op_SpecInterface(i8* %ciphertext, [5 x i8]* @p_str4, i32 1, i32 1, [5 x i8]* @p_str5, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str)
  call void (...)* @_ssdm_op_SpecInterface(i8* %expandedKey, [5 x i8]* @p_str4, i32 1, i32 1, [5 x i8]* @p_str5, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str)
  call void (...)* @_ssdm_op_SpecInterface(i8* %plaintext, [5 x i8]* @p_str4, i32 1, i32 1, [5 x i8]* @p_str5, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str)
  call void (...)* @_ssdm_op_SpecResourceLimit(i32 1, [1 x i8]* @p_str, [1 x i8]* @p_str, [12 x i8]* @p_str6, [1 x i8]* @p_str) nounwind
  br label %1

; <label>:1                                       ; preds = %2, %0
  %i = phi i5 [ 0, %0 ], [ %i_3, %2 ]
  %tmp = icmp eq i5 %i, -16
  %i_3 = add i5 %i, 1
  br i1 %tmp, label %3, label %2

; <label>:2                                       ; preds = %1
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 16, i64 16, i64 16) nounwind
  call void (...)* @_ssdm_op_SpecLoopName([7 x i8]* @p_str9) nounwind
  %tmp_1 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str9) nounwind
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %tmp_18 = zext i5 %i to i64
  %ciphertext_read = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %ciphertext) nounwind
  %state_addr_31 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 %tmp_18
  store i8 %ciphertext_read, i8* %state_addr_31, align 1
  %empty_6 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str9, i32 %tmp_1) nounwind
  br label %1

; <label>:3                                       ; preds = %1
  %tmp_cast = zext i16 %Nr_read to i17
  call fastcc void @AddRoundKey([16 x i8]* %state, i8* %expandedKey) nounwind
  %tmp_s = add i17 %tmp_cast, -1
  br label %4

; <label>:4                                       ; preds = %._crit_edge, %3
  %i1 = phi i16 [ 0, %3 ], [ %i_4, %._crit_edge ]
  %exitcond = icmp eq i16 %i1, %Nr_read
  %i_4 = add i16 %i1, 1
  br i1 %exitcond, label %.preheader.0, label %5

; <label>:5                                       ; preds = %4
  call void (...)* @_ssdm_op_SpecLoopName([9 x i8]* @p_str10) nounwind
  call fastcc void @InvShiftRows([16 x i8]* %state) nounwind
  call fastcc void @InvSubBytes([16 x i8]* %state) nounwind
  %tmp_67_cast = zext i16 %i1 to i17
  call fastcc void @AddRoundKey([16 x i8]* %state, i8* %expandedKey) nounwind
  %tmp_19 = icmp eq i17 %tmp_67_cast, %tmp_s
  br i1 %tmp_19, label %._crit_edge, label %6

; <label>:6                                       ; preds = %5
  call fastcc void @InvMixColumns([16 x i8]* %state) nounwind
  br label %._crit_edge

._crit_edge:                                      ; preds = %6, %5
  br label %4

.preheader.0:                                     ; preds = %4
  %state_addr = getelementptr inbounds [16 x i8]* %state, i64 0, i64 0
  %state_load = load i8* %state_addr, align 16
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load) nounwind
  %state_addr_63 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 1
  %state_load_1 = load i8* %state_addr_63, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_1) nounwind
  %state_addr_64 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 2
  %state_load_2 = load i8* %state_addr_64, align 2
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_2) nounwind
  %state_addr_65 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 3
  %state_load_3 = load i8* %state_addr_65, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_3) nounwind
  %state_addr_66 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 4
  %state_load_4 = load i8* %state_addr_66, align 4
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_4) nounwind
  %state_addr_67 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 5
  %state_load_5 = load i8* %state_addr_67, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_5) nounwind
  %state_addr_68 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 6
  %state_load_6 = load i8* %state_addr_68, align 2
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_6) nounwind
  %state_addr_69 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 7
  %state_load_7 = load i8* %state_addr_69, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_7) nounwind
  %state_addr_70 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 8
  %state_load_8 = load i8* %state_addr_70, align 8
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_8) nounwind
  %state_addr_71 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 9
  %state_load_9 = load i8* %state_addr_71, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_9) nounwind
  %state_addr_72 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 10
  %state_load_10 = load i8* %state_addr_72, align 2
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_10) nounwind
  %state_addr_73 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 11
  %state_load_11 = load i8* %state_addr_73, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_11) nounwind
  %state_addr_74 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 12
  %state_load_12 = load i8* %state_addr_74, align 4
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_12) nounwind
  %state_addr_75 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 13
  %state_load_13 = load i8* %state_addr_75, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_13) nounwind
  %state_addr_76 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 14
  %state_load_14 = load i8* %state_addr_76, align 2
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_14) nounwind
  %state_addr_77 = getelementptr inbounds [16 x i8]* %state, i64 0, i64 15
  %state_load_15 = load i8* %state_addr_77, align 1
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %plaintext, i8 %state_load_15) nounwind
  ret void
}

!opencl.kernels = !{!0, !0, !0, !0, !0, !0, !7, !13, !19, !21, !21}
!hls.encrypted.func = !{}
!llvm.map.gv = !{!27}

!0 = metadata !{null, metadata !1, metadata !2, metadata !3, metadata !4, metadata !5, metadata !6}
!1 = metadata !{metadata !"kernel_arg_addr_space", i32 1}
!2 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none"}
!3 = metadata !{metadata !"kernel_arg_type", metadata !"uchar*"}
!4 = metadata !{metadata !"kernel_arg_type_qual", metadata !""}
!5 = metadata !{metadata !"kernel_arg_name", metadata !"state"}
!6 = metadata !{metadata !"reqd_work_group_size", i32 1, i32 1, i32 1}
!7 = metadata !{null, metadata !8, metadata !9, metadata !10, metadata !11, metadata !12, metadata !6}
!8 = metadata !{metadata !"kernel_arg_addr_space", i32 1, i32 1}
!9 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none"}
!10 = metadata !{metadata !"kernel_arg_type", metadata !"uchar*", metadata !"uchar*"}
!11 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !""}
!12 = metadata !{metadata !"kernel_arg_name", metadata !"state", metadata !"roundKey"}
!13 = metadata !{null, metadata !14, metadata !15, metadata !16, metadata !17, metadata !18, metadata !6}
!14 = metadata !{metadata !"kernel_arg_addr_space", i32 1, i32 1, i32 0, i32 1}
!15 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none", metadata !"none", metadata !"none"}
!16 = metadata !{metadata !"kernel_arg_type", metadata !"uchar*", metadata !"uchar*", metadata !"ushort", metadata !"uchar*"}
!17 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !"", metadata !"", metadata !""}
!18 = metadata !{metadata !"kernel_arg_name", metadata !"plaintext", metadata !"expandedKey", metadata !"Nr", metadata !"ciphertext"}
!19 = metadata !{null, metadata !14, metadata !15, metadata !16, metadata !17, metadata !20, metadata !6}
!20 = metadata !{metadata !"kernel_arg_name", metadata !"ciphertext", metadata !"expandedKey", metadata !"Nr", metadata !"plaintext"}
!21 = metadata !{null, metadata !22, metadata !23, metadata !24, metadata !25, metadata !26, metadata !6}
!22 = metadata !{metadata !"kernel_arg_addr_space"}
!23 = metadata !{metadata !"kernel_arg_access_qual"}
!24 = metadata !{metadata !"kernel_arg_type"}
!25 = metadata !{metadata !"kernel_arg_type_qual"}
!26 = metadata !{metadata !"kernel_arg_name"}
!27 = metadata !{metadata !28, [1 x i32]* @llvm_global_ctors_0}
!28 = metadata !{metadata !29}
!29 = metadata !{i32 0, i32 31, metadata !30}
!30 = metadata !{metadata !31}
!31 = metadata !{metadata !"llvm.global_ctors.0", metadata !32, metadata !"", i32 0, i32 31}
!32 = metadata !{metadata !33}
!33 = metadata !{i32 0, i32 0, i32 1}
!34 = metadata !{metadata !35}
!35 = metadata !{i32 0, i32 7, metadata !36}
!36 = metadata !{metadata !37}
!37 = metadata !{metadata !"ciphertext", metadata !38, metadata !"unsigned char", i32 0, i32 7}
!38 = metadata !{metadata !39}
!39 = metadata !{i32 0, i32 15, i32 1}
!40 = metadata !{metadata !41}
!41 = metadata !{i32 0, i32 7, metadata !42}
!42 = metadata !{metadata !43}
!43 = metadata !{metadata !"expandedKey", metadata !44, metadata !"unsigned char", i32 0, i32 7}
!44 = metadata !{metadata !45}
!45 = metadata !{i32 0, i32 239, i32 1}
!46 = metadata !{metadata !47}
!47 = metadata !{i32 0, i32 15, metadata !48}
!48 = metadata !{metadata !49}
!49 = metadata !{metadata !"Nr", metadata !50, metadata !"unsigned short", i32 0, i32 15}
!50 = metadata !{metadata !51}
!51 = metadata !{i32 0, i32 0, i32 0}
!52 = metadata !{metadata !53}
!53 = metadata !{i32 0, i32 7, metadata !54}
!54 = metadata !{metadata !55}
!55 = metadata !{metadata !"plaintext", metadata !38, metadata !"unsigned char", i32 0, i32 7}
